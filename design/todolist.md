# LifeLog.ai 開發任務清單（Demo 優先版）

## 專案狀態概覽

- **開始日期**: 2025-10-20
- **目標**: 完成可展示的 Demo 流程
- **策略**: 先求能跑，不求完美；專注核心流程
- **影片**: 現場錄製 10 分鐘即可

---

## 📋 任務優先級

### 🔥 P0 - 核心必須（Demo 必備）
### 🟡 P1 - 重要（Demo 加分）
### 🟢 P2 - 次要（時間允許再做）
### ⚪ P3 - 暫緩（Demo 後再說）

---

## Demo 流程檢查清單

根據需求，Demo 需要完成以下步驟：

- [x] ✅ 登入系統（已實作）
- [x] ✅ 透過系統取得連線連結（已實作）
- [x] ✅ 透過連結將 IP Camera 連線至系統（已實作）
- [ ] 🔥 錄製 10 分鐘的影片
- [ ] 🔥 可以查看影片的事件
- [ ] 🔥 可以透過自然語言詢問某段時間的事件
- [ ] 🔥 可以在 vlog 頁面勾選目標影片（手動勾選優先）
- [ ] 🔥 按下確認後將影片送入剪接模型剪接至目標秒數
- [ ] 🟡 使用者可以觀看影片與下載影片
- [ ] 🟡 使用者可以查看一天的事件總結

---

## 第 1 階段：基礎功能確保（優先度 P0）

### 1.1 確認現有錄影功能正常 🔥
**預計時間**: 30 分鐘

- [ ] **1.1.1** 測試完整錄影流程
  - [ ] 啟動 Docker Compose 環境
  - [ ] 登入系統並取得攝影機連結
  - [ ] 使用 `ip_camera_sim.py` 推流 10 分鐘
  - [ ] 確認影片自動分段錄製
  - [ ] 確認影片上傳到 MinIO
  - [ ] 確認 ComputeServer 自動處理影片

- [ ] **1.1.2** 檢查事件生成
  - [ ] 確認影片分析任務執行
  - [ ] 確認事件資料寫入資料庫
  - [ ] 確認事件包含 action, scene, summary
  - [ ] 如果失敗，檢查 ComputeServer 日誌

**交付物**:
- [ ] 錄製的 10 分鐘測試影片
- [ ] 生成的事件資料（至少 3-5 個事件）

**備註**: 現有系統應該已經可以做到這步，主要是驗證功能正常

---

### 1.2 前端事件列表頁面（簡易版）🔥
**預計時間**: 2-3 小時

- [ ] **1.2.1** 修改現有 `view.html` 或新建頁面
  - [ ] 新增「事件列表」區塊
  - [ ] 呼叫 `GET /api/v1/events` API
  - [ ] 顯示事件列表（時間、場景、動作、摘要）
  - [ ] 點擊事件可查看詳細資訊
  - [ ] 簡單的時間軸視圖（可選）

- [ ] **1.2.2** 測試與調整
  - [ ] 測試載入事件列表
  - [ ] 測試事件篩選（按日期、場景）
  - [ ] 確認顯示正常

**交付物**:
- [ ] 可用的事件列表頁面
- [ ] 能正確顯示 10 分鐘影片的事件

**備註**: 
- 使用 Vanilla JS 快速開發，不需要框架
- UI 簡單即可，重點是功能可用
- 可以參考現有 `view.html` 的風格

---

## 第 2 階段：自然語言查詢（優先度 P0）

### 2.1 自然語言查詢 API（簡化版）🔥
**預計時間**: 3-4 小時

- [ ] **2.1.1** 建立 API 端點
  - [ ] 新增 `POST /api/v1/query/natural-language` 端點
  - [ ] 使用 Google Gemini 解析查詢意圖
  - [ ] 構建簡單的資料庫查詢
  - [ ] 回傳匹配的事件列表

- [ ] **2.1.2** 簡化版查詢引擎
  ```python
  # 簡化策略：
  # 1. 直接用 LLM 解析查詢 → 提取時間、場景、動作關鍵字
  # 2. 用關鍵字做模糊匹配查詢資料庫
  # 3. 回傳前 5 個最相關的事件
  # 4. 用 LLM 生成簡單的回答文字
  ```

- [ ] **2.1.3** DTO 定義
  - [ ] `QueryRequest`: query, user_id, date_range
  - [ ] `QueryResponse`: answer, events, confidence

**交付物**:
- [ ] 可用的查詢 API
- [ ] 支援基本查詢（時間、場景、動作）

**備註**:
- **不需要** Vector Database
- **不需要** 複雜的意圖分類
- 簡單的關鍵字匹配 + LLM 就夠了

---

### 2.2 前端查詢介面 🔥
**預計時間**: 1-2 小時

- [ ] **2.2.1** 新增查詢區塊
  - [ ] 查詢輸入框
  - [ ] 提交按鈕
  - [ ] 結果顯示區（回答文字 + 事件卡片）
  - [ ] 點擊事件可查看影片

- [ ] **2.2.2** 預設查詢建議（hardcode）
  - [ ] 「我今天幾點吃飯？」
  - [ ] 「我今天去了哪裡？」
  - [ ] 「我今天在客廳做了什麼？」

**交付物**:
- [ ] 可用的查詢介面
- [ ] 至少能正確回答 3 種基本查詢

**備註**:
- 重點是展示「自然語言理解」的能力
- 不需要很完美，能展示就好

---

## 第 3 階段：Vlog 生成（優先度 P0）

### 3.1 資料庫擴充 🔥
**預計時間**: 30 分鐘

- [ ] **3.1.1** 新增 `vlogs` 資料表
  - [ ] 複製 spec.md 的 SQL 建立 migration
  - [ ] 執行 migration
  - [ ] 建立對應的 SQLAlchemy Model
  - [ ] 建立 Pydantic Schema

- [ ] **3.1.2** 新增 `vlog_segments` 資料表（簡化版）
  - [ ] 只保留必要欄位：vlog_id, recording_id, start_offset, end_offset
  - [ ] 執行 migration

**交付物**:
- [ ] 兩個新資料表
- [ ] 可以存取的 Model

**備註**:
- 暫時不需要 `daily_summaries` 資料表
- 結構先求簡單，能用就好

---

### 3.2 Vlog 生成 API（手動模式優先）🔥
**預計時間**: 4-5 小時

- [ ] **3.2.1** 建立 Vlog API 端點
  - [ ] `POST /api/v1/vlogs` - 建立 Vlog
  - [ ] `GET /api/v1/vlogs` - 列表查詢
  - [ ] `GET /api/v1/vlogs/{id}` - 取得詳情 + 下載 URL
  - [ ] 暫時不做刪除功能

- [ ] **3.2.2** 簡化版 Vlog Generator（ComputeServer）
  ```python
  # 簡化流程：
  # 1. 接收使用者選擇的片段（recording_id + 時間範圍）
  # 2. 從 MinIO 下載對應影片
  # 3. 用 FFmpeg 裁切並合併片段
  # 4. 簡單的淡入淡出轉場（xfade filter）
  # 5. 不加音樂、不加字幕（時間不夠可以跳過）
  # 6. 上傳結果到 MinIO
  # 7. 更新資料庫
  ```

- [ ] **3.2.3** Celery 任務
  - [ ] `tasks.generate_vlog` 任務
  - [ ] 回報進度（processing → completed/failed）
  - [ ] 錯誤處理

**交付物**:
- [ ] 可用的 Vlog 生成功能
- [ ] 能合併 2-3 段影片
- [ ] 生成 15-30 秒的 Vlog

**備註**:
- **優先做手動模式**（使用者自己選片段）
- AI 自動選擇如果時間不夠就跳過
- 音樂和字幕是加分項，可以最後再做

---

### 3.3 前端 Vlog 建立頁面 🔥
**預計時間**: 3-4 小時

- [ ] **3.3.1** Vlog 建立介面
  - [ ] 顯示當日所有事件（含影片縮圖）
  - [ ] 勾選要合併的片段
  - [ ] 設定目標時長（例如 30 秒）
  - [ ] 提交生成 Vlog

- [ ] **3.3.2** Vlog 列表與播放
  - [ ] 顯示已生成的 Vlog 列表
  - [ ] 點擊可播放
  - [ ] 下載按鈕

**交付物**:
- [ ] 可用的 Vlog 建立頁面
- [ ] 可以勾選片段並生成
- [ ] 可以播放和下載

**備註**:
- UI 簡單就好
- 重點是功能可用，展示「AI 剪輯」概念

---

## 第 4 階段：每日日誌（優先度 P1）

### 4.1 每日日誌 API（簡化版）🟡
**預計時間**: 2-3 小時

- [ ] **4.1.1** 日誌生成邏輯
  ```python
  # 簡化版：
  # 1. 查詢當日所有事件
  # 2. 統計場景、動作分佈
  # 3. 用 LLM 生成一段流暢的日誌文字
  # 4. 暫時不存資料庫，直接回傳
  ```

- [ ] **4.1.2** API 端點
  - [ ] `GET /api/v1/daily-summaries/{date}` - 取得日誌
  - [ ] 動態生成（不需要 Celery 任務）

**交付物**:
- [ ] 可用的日誌生成 API
- [ ] 能生成流暢的日誌文字

**備註**:
- 這是加分項，Demo 時展示即可
- 如果時間不夠可以用假資料

---

### 4.2 前端日誌頁面 🟡
**預計時間**: 1-2 小時

- [ ] **4.2.1** 日誌顯示頁面
  - [ ] 選擇日期
  - [ ] 顯示日誌文字
  - [ ] 顯示統計資料（場景、動作分佈）
  - [ ] 事件時間軸

**交付物**:
- [ ] 可用的日誌頁面

---

## 第 5 階段：整合測試與 Demo 準備（優先度 P0）

### 5.1 端到端測試 🔥
**預計時間**: 2-3 小時

- [ ] **5.1.1** 完整流程測試
  - [ ] 啟動 Docker Compose
  - [ ] 登入系統
  - [ ] 推流 10 分鐘
  - [ ] 等待事件生成
  - [ ] 查看事件列表 ✓
  - [ ] 測試自然語言查詢 ✓
  - [ ] 建立 Vlog（手動選 2-3 段）✓
  - [ ] 等待 Vlog 生成
  - [ ] 播放和下載 Vlog ✓
  - [ ] 查看每日日誌 ✓

- [ ] **5.1.2** Bug 修復
  - [ ] 記錄所有問題
  - [ ] 修復 P0 問題（阻礙 Demo 的）
  - [ ] P1/P2 問題記錄但不修（時間不夠）

**交付物**:
- [ ] 完整的測試報告
- [ ] 可展示的系統

---

### 5.2 Demo 腳本與資料準備 🔥
**預計時間**: 2 小時

- [ ] **5.2.1** Demo 腳本
  ```
  1. [1min] 系統介紹：LifeLog.ai 是什麼
  2. [2min] 推流與錄影：展示攝影機連線
  3. [1min] 事件識別：展示 AI 分析結果
  4. [2min] 自然語言查詢：展示 3 個查詢範例
  5. [2min] Vlog 生成：展示手動選片與生成
  6. [1min] 每日日誌：展示日誌摘要
  7. [1min] 總結與 Q&A
  ```

- [ ] **5.2.2** 測試資料準備
  - [ ] 準備 1 段 10 分鐘的示範影片
  - [ ] 確保影片包含多種場景（廚房、客廳、室外）
  - [ ] 確保影片包含多種動作（吃飯、使用電腦、走動）
  - [ ] 提前錄製好備用

- [ ] **5.2.3** 備用方案
  - [ ] 如果現場推流失敗，用預錄影片
  - [ ] 如果 Vlog 生成太慢，展示預先做好的
  - [ ] 如果 LLM 回答不好，準備說明「還在優化中」

**交付物**:
- [ ] Demo 腳本文件
- [ ] 測試資料（影片）
- [ ] 備用方案清單

---

### 5.3 簡報製作 🔥
**預計時間**: 2-3 小時

- [ ] **5.3.1** 簡報內容
  - [ ] 封面：LifeLog.ai - AI 生活日誌系統
  - [ ] 問題背景：為什麼需要自動生活記錄？
  - [ ] 系統架構：微服務架構圖
  - [ ] 核心功能：
    - 自動錄影與事件識別
    - 自然語言查詢
    - Vlog 自動生成
    - 每日日誌總結
  - [ ] 技術亮點：
    - OpenCV + BLIP + Gemini 的 AI pipeline
    - FFmpeg 影片處理
    - 微服務架構
  - [ ] Demo 展示（截圖或影片）
  - [ ] 未來展望

**交付物**:
- [ ] PPT/PDF 簡報檔案
- [ ] Demo 影片（備用）

---

## 📊 任務時間估算

### 依優先級分配

| 階段 | 優先級 | 預計時間 | 內容 |
| --- | --- | --- | --- |
| 第 1 階段 | P0 🔥 | 2.5-3.5h | 確認錄影 + 事件列表頁面 |
| 第 2 階段 | P0 🔥 | 4-6h | 自然語言查詢 API + 前端 |
| 第 3 階段 | P0 🔥 | 8-10h | Vlog 功能（DB + API + 前端）|
| 第 4 階段 | P1 🟡 | 3-5h | 每日日誌（可選）|
| 第 5 階段 | P0 🔥 | 6-8h | 測試 + Demo 準備 + 簡報 |

**總計**: 23.5-32.5 小時（約 3-4 個工作天）

### 建議排程

- **Day 1** (8h): 第 1-2 階段（事件列表 + 查詢功能）
- **Day 2** (8h): 第 3 階段前半（Vlog DB + API）
- **Day 3** (8h): 第 3 階段後半 + 第 4 階段（Vlog 前端 + 日誌）
- **Day 4** (8h): 第 5 階段（測試 + Demo 準備）

---

## 🎯 關鍵成功因素

### ✅ 必須做到
1. **錄影 10 分鐘並生成事件** - 核心功能
2. **自然語言查詢** - 展示 AI 理解能力
3. **Vlog 手動生成** - 展示影片剪輯能力
4. **完整的 Demo 流程** - 能跑通全流程

### 🟡 盡量做到
1. **Vlog AI 自動選片** - 展示 AI 智能
2. **每日日誌生成** - 展示文字生成能力
3. **漂亮的 UI** - 加分但不是重點

### ⚪ 可以跳過
1. **音樂混音** - 時間不夠就不做
2. **字幕生成** - 時間不夠就不做
3. **複雜的轉場** - 簡單淡入淡出就好
4. **Vector Database** - 用不到
5. **進階影片編輯** - Demo 後再說

---

## 🛠️ 開發技巧

### 快速開發策略

1. **複製貼上優先**
   - 參考現有 API 端點的結構
   - 複製現有的 DTO 定義
   - 複製現有的前端元件

2. **Hardcode 優先**
   - 查詢建議可以 hardcode
   - 場景列表可以 hardcode
   - 音樂可以只有一首

3. **簡化邏輯**
   - AI 選片不夠智能？沒關係，隨機選也行
   - 查詢不夠準確？沒關係，盡力就好
   - UI 不夠漂亮？沒關係，能用就行

4. **善用工具**
   - ChatGPT 生成程式碼框架
   - Claude 協助 Debug
   - 善用現有的 FFmpeg 範例

---

## ⚠️ 風險與備案

### 風險 1：Vlog 生成太慢
- **緩解**: 降低影片品質、減少片段數
- **備案**: 提前生成好範例，Demo 時播放

### 風險 2：LLM 回答不準確
- **緩解**: 準備固定的測試查詢
- **備案**: 說明「還在優化中」，展示理解意圖的能力即可

### 風險 3：前端開發時間不足
- **緩解**: 用最簡單的 HTML + JS
- **備案**: 用 Swagger UI 展示 API，說明「前端還在開發中」

### 風險 4：整合測試失敗
- **緩解**: 每完成一個階段就測試
- **備案**: 準備錄影展示，不做現場 Demo

---

## 📝 開發檢查清單

### 每日檢查
- [ ] 當日任務是否完成？
- [ ] 是否有阻礙進度的問題？
- [ ] 需要調整計畫嗎？

### 開發前檢查
- [ ] Docker Compose 啟動成功？
- [ ] 所有服務健康檢查通過？
- [ ] 測試資料準備好了嗎？

### Demo 前檢查
- [ ] 端到端流程測試通過？
- [ ] Demo 腳本準備好了嗎？
- [ ] 備用方案準備好了嗎？
- [ ] 簡報製作完成了嗎？

---

## 📞 求助清單

### 如果遇到問題

1. **ComputeServer 任務失敗**
   - 檢查 Celery Worker 日誌
   - 檢查 Redis 連線
   - 檢查 MinIO 連線
   - 檢查環境變數

2. **影片生成失敗**
   - 檢查 FFmpeg 命令
   - 檢查影片格式
   - 降低品質設定
   - 減少片段數

3. **LLM 回答怪異**
   - 檢查 Prompt 設計
   - 檢查 API Key
   - 增加範例
   - 簡化查詢

4. **前端無法連線 API**
   - 檢查 CORS 設定
   - 檢查 API Base URL
   - 檢查 JWT Token
   - 查看瀏覽器 Console

---

**最後更新**: 2025-10-20  
**版本**: v2.0 (Demo 優先版)  
**維護者**: LifeLog.ai 開發團隊

---

## 💡 重要提醒

> **記住**: Demo 的目標是展示**概念**與**可行性**，不是展示完美的產品。
> 
> - ✅ 先求有，再求好
> - ✅ 能跑就是好的開始
> - ✅ Bug 可以解釋，但不能完全不能跑
> - ✅ UI 醜沒關係，功能對才重要
> - ✅ 效能慢沒關係，能展示就好
> 
> **最重要的是**: 展示完整的流程！🎯
