# -*- coding: utf-8 -*-
from __future__ import annotations
import os
import uuid
from typing import Optional, List, Tuple
from datetime import date, datetime, time, timedelta, timezone

import boto3
from botocore.config import Config

from fastapi import APIRouter, Depends, HTTPException, status, Query, Path, Request
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, func, and_, or_, delete, exists

from ...DataAccess.Connect import get_session
from ...DataAccess.tables import recordings as recordings_table  # recordings_table.Table
from ...DataAccess.tables import events as events_table          # events_table.Table
from ...router.User.service import UserService

from .DTO import (
    RecordingRead, RecordingListResp, RecordingUrlResp, OkResp, EventRead
)

# ------------------------------------------------------------
# Router
# ------------------------------------------------------------
recordings_router = APIRouter(prefix="/recordings", tags=["recordings"])
# æ©Ÿå™¨å°æ©Ÿå™¨ï¼ˆCompute/Streamingï¼‰ç”¨ï¼šç”¨ X-API-Key æˆæ¬Šï¼Œä¸èµ°ä¸€èˆ¬ä½¿ç”¨è€… JWT
recordings_m2m_router = APIRouter(prefix="/m2m/recordings", tags=["m2m"])

# ------------------------------------------------------------
# User Service å¯¦ä¾‹
# ------------------------------------------------------------
user_service = UserService()

# ------------------------------------------------------------
# S3/MinIOï¼šä½ å¯æŠŠä¸‹åˆ—å…©å‡½å¼æ”¹æˆä½ ã€Œå·²é©—è­‰æˆåŠŸã€çš„å°è£
# ------------------------------------------------------------
# å…§éƒ¨ä½¿ç”¨çš„ endpointï¼ˆDocker ç¶²çµ¡å…§ï¼‰
INTERNAL_MINIO_ENDPOINT = os.getenv("MINIO_ENDPOINT", "http://minio:9000")

# å¤–éƒ¨å¯é”çš„ endpointï¼ˆç€è¦½å™¨è¨ªå•ï¼‰
# å„ªå…ˆä½¿ç”¨æ–°çš„ç’°å¢ƒè®Šæ•¸é…ç½®ï¼Œå¦å‰‡ä½¿ç”¨èˆŠçš„ PUBLIC_MINIO_ENDPOINT
def _get_public_minio_endpoint() -> str:
    """ç²å– MinIO å…¬é–‹ç«¯é»ï¼Œç”¨æ–¼ç”Ÿæˆ presigned URL"""
    minio_domain = os.getenv("MINIO_PUBLIC_DOMAIN", "").strip()
    if minio_domain:
        scheme = os.getenv("MINIO_PUBLIC_SCHEME", "http").strip()
        port_str = os.getenv("MINIO_PUBLIC_PORT", "").strip()
        
        if port_str:
            try:
                port = int(port_str)
                if (scheme == "http" and port == 80) or (scheme == "https" and port == 443):
                    return f"{scheme}://{minio_domain}"
                return f"{scheme}://{minio_domain}:{port}"
            except ValueError:
                pass
        
        return f"{scheme}://{minio_domain}"
    
    # å‘å¾Œå…¼å®¹ï¼šä½¿ç”¨èˆŠçš„ç’°å¢ƒè®Šæ•¸
    old_endpoint = os.getenv("PUBLIC_MINIO_ENDPOINT", "")
    if old_endpoint:
        return old_endpoint
    
    # å¦‚æœå®Œå…¨æ²’æœ‰è¨­å®šï¼Œè¿”å›ç©ºå­—ä¸²ï¼ˆæœƒåœ¨ä½¿ç”¨æ™‚è§¸ç™¼éŒ¯èª¤ï¼Œæé†’è¨­å®šç’°å¢ƒè®Šæ•¸ï¼‰
    # æ³¨æ„ï¼šç”Ÿç”¢ç’°å¢ƒæ‡‰è©²åœ¨ .env ä¸­æ˜ç¢ºè¨­å®š MINIO_PUBLIC_DOMAIN æˆ– PUBLIC_MINIO_ENDPOINT
    return ""

PUBLIC_MINIO_ENDPOINT = _get_public_minio_endpoint()

# S3 å®¢æˆ¶ç«¯ä½¿ç”¨å…§éƒ¨ endpointï¼ˆæœå‹™å™¨ç«¯è¨ªå•ï¼‰
S3_ENDPOINT   = INTERNAL_MINIO_ENDPOINT
S3_ACCESS_KEY = os.getenv("MINIO_ROOT_USER",  os.getenv("S3_ACCESS_KEY", "minioadmin"))
S3_SECRET_KEY = os.getenv("MINIO_ROOT_PASSWORD", os.getenv("S3_SECRET_KEY", "minioadmin"))
S3_REGION     = os.getenv("AWS_REGION", "us-east-1")
S3_BUCKET     = os.getenv("MINIO_BUCKET", "media-bucket")

# ä¸€å¾‹ç”¨ path-styleï¼Œé¿å…è®Šæˆ videos.minio:30300 é€™ç¨®å¤–éƒ¨è§£æä¸åˆ°çš„å­ç¶²åŸŸ
_s3 = boto3.client(
    "s3",
    endpoint_url=S3_ENDPOINT,
    aws_access_key_id=S3_ACCESS_KEY,
    aws_secret_access_key=S3_SECRET_KEY,
    region_name=S3_REGION,
    config=Config(
        signature_version="s3v4",
        s3={"addressing_style": "path"}   # â† é—œéµ
    ),
)

def _normalize_key(key: str) -> str:
    """æ­£è¦åŒ– S3 keyï¼Œç§»é™¤ s3:// å‰ç¶´å’Œ bucket åç¨±ã€‚
    
    è™•ç†å„ç¨®æ ¼å¼çš„ S3 keyï¼Œç¢ºä¿è¿”å›ä¹¾æ·¨çš„ key è·¯å¾‘ã€‚
    æ”¯æ´ s3://bucket/keyã€bucket/key å’Œç›´æ¥ key æ ¼å¼ã€‚
    
    Args:
        key: åŸå§‹ S3 keyï¼ˆå¯èƒ½åŒ…å« s3:// å‰ç¶´å’Œ bucket åç¨±ï¼‰
        
    Returns:
        str: æ­£è¦åŒ–å¾Œçš„ key
        
    Raises:
        ValueError: ç•¶ key ç‚ºç©ºæˆ–æ­£è¦åŒ–å¾Œç‚ºç©ºæ™‚
    """
    if not key:
        raise ValueError("S3 key cannot be empty")
    
    # ç§»é™¤ s3://bucket/... å‰ç¶´
    if key.startswith("s3://"):
        without_scheme = key.split("://", 1)[1]
        # å»æ‰å‰é¢çš„ bucket åï¼ˆä¸ç®¡å®ƒæ˜¯ videos é‚„æ˜¯ media-bucketï¼‰
        if "/" in without_scheme:
            without_scheme = without_scheme.split("/", 1)[1]
        key = without_scheme

    # è‹¥ key ä»ä»¥ä»»ä¸€ bucket åé–‹é ­ï¼ˆvideos/ æˆ– media-bucket/ï¼‰ï¼Œç§»é™¤ä¹‹
    for b in (os.getenv("S3_BUCKET", ""), "videos", "media-bucket"):
        if b and key.startswith(f"{b}/"):
            key = key[len(b) + 1 :]
            break

    # æ¸…ç†å¤šé¤˜çš„æ–œç·šå’Œç©ºæ ¼ï¼Œç¢ºä¿æ ¼å¼æ­£ç¢º
    # ç§»é™¤é–‹é ­å’Œçµå°¾çš„æ–œç·š
    key = key.strip("/")
    # å°‡å¤šå€‹é€£çºŒæ–œç·šæ›¿æ›ç‚ºå–®å€‹æ–œç·š
    while "//" in key:
        key = key.replace("//", "/")
    # ç§»é™¤é–‹é ­å’Œçµå°¾çš„ç©ºæ ¼
    key = key.strip()
    
    # é©—è­‰ key ä¸ç‚ºç©ºï¼ˆå¦‚æœç‚ºç©ºèªªæ˜åŸå§‹ key æœ‰å•é¡Œï¼‰
    if not key:
        raise ValueError("Normalized S3 key is empty after processing")
    
    return key

def _presign_get(
    key: str,
    ttl: int,
    *,
    disposition: Optional[str] = None,
    filename: Optional[str] = None,
    content_type: Optional[str] = None,
) -> str:
    key = _normalize_key(key)  # å¦‚æœä½ æœ‰é€™æ”¯ï¼Œä¿ç•™
    params = {"Bucket": S3_BUCKET, "Key": key}

    # æ ¹æ“šæ–‡ä»¶é¡å‹è¨­ç½® ContentTypeï¼ˆç¸®åœ–ç‚º image/jpegï¼Œå½±ç‰‡ç‚º video/mp4ï¼‰
    if content_type:
        params["ResponseContentType"] = content_type
    else:
        # æ ¹æ“š key çš„å‰¯æª”ååˆ¤æ–·é¡å‹
        if key.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.webp')):
            params["ResponseContentType"] = "image/jpeg"
        else:
            params["ResponseContentType"] = "video/mp4"

    # é è¨­ inlineï¼›è‹¥ä½ å¾ query å‚³é€²ä¾†å°±å°Šé‡ä½¿ç”¨è€…
    disp = disposition or "inline"
    safe_name = filename or key.rsplit("/", 1)[-1]
    params["ResponseContentDisposition"] = f'{disp}; filename="{safe_name}"'

    # å¦‚æœå…§éƒ¨å’Œå¤–éƒ¨çš„ endpoint ä¸åŒï¼Œéœ€è¦å‰µå»ºå¤–éƒ¨å®¢æˆ¶ç«¯ä¾†ç”Ÿæˆé ç°½å URL
    # å› ç‚ºé ç°½å URL çš„ç°½åæ˜¯åŸºæ–¼ host çš„ï¼Œä¸èƒ½ç›´æ¥æ›¿æ› host
    if PUBLIC_MINIO_ENDPOINT and INTERNAL_MINIO_ENDPOINT != PUBLIC_MINIO_ENDPOINT:
        # å‰µå»ºå¤–éƒ¨ S3 å®¢æˆ¶ç«¯ï¼ˆç”¨æ–¼ç”Ÿæˆç€è¦½å™¨å¯è¨ªå•çš„é ç°½å URLï¼‰
        _s3_public = boto3.client(
            "s3",
            endpoint_url=PUBLIC_MINIO_ENDPOINT,
            aws_access_key_id=S3_ACCESS_KEY,
            aws_secret_access_key=S3_SECRET_KEY,
            region_name=S3_REGION,
            config=Config(
                signature_version="s3v4",
                s3={"addressing_style": "path"}
            ),
        )
        presigned_url = _s3_public.generate_presigned_url("get_object", Params=params, ExpiresIn=int(ttl))
    else:
        # å¦‚æœå…¬é–‹ç«¯é»æœªè¨­å®šï¼Œè¨˜éŒ„è­¦å‘Šä½†ç¹¼çºŒä½¿ç”¨å…§éƒ¨ç«¯é»
        if not PUBLIC_MINIO_ENDPOINT:
            print("[WARNING] PUBLIC_MINIO_ENDPOINT not set, using internal endpoint. External access may fail.")
        # å¦‚æœå…§éƒ¨å¤–éƒ¨ç›¸åŒï¼Œç›´æ¥ä½¿ç”¨å…§éƒ¨å®¢æˆ¶ç«¯
        presigned_url = _s3.generate_presigned_url("get_object", Params=params, ExpiresIn=int(ttl))
    
    return presigned_url

def _delete_object(key: str) -> None:
    """åˆªé™¤ç‰©ä»¶ï¼›ä¸å­˜åœ¨ä¹Ÿè¦–ç‚ºæˆåŠŸï¼ˆS3 çš„èªæ„å³æ˜¯å†ªç­‰ï¼‰ã€‚"""
    # æ­£è¦åŒ– keyï¼Œç¢ºä¿æ ¼å¼æ­£ç¢º
    normalized_key = _normalize_key(key)
    try:
        _s3.delete_object(Bucket=S3_BUCKET, Key=normalized_key)
    except Exception as e:
        # è¨˜éŒ„éŒ¯èª¤è©³æƒ…ä»¥ä¾¿èª¿è©¦
        print(f"[Delete Object Error] Original key: {key}")
        print(f"[Delete Object Error] Normalized key: {normalized_key}")
        print(f"[Delete Object Error] Error: {e}")
        raise

# ------------------------------------------------------------
# Utils
# ------------------------------------------------------------
def _date_to_utc_range(d: date, user_timezone: str = "Asia/Taipei") -> Tuple[datetime, datetime]:
    """æŠŠ local ISO date è½‰ç‚ºè©²æ—¥ UTC [00:00, æ¬¡æ—¥00:00)ã€‚ä½¿ç”¨ä½¿ç”¨è€…æ™‚å€é€²è¡Œè½‰æ›ã€‚"""
    import pytz
    
    # ç²å–ä½¿ç”¨è€…æ™‚å€
    user_tz = pytz.timezone(user_timezone)
    
    # åœ¨ä½¿ç”¨è€…æ™‚å€ä¸­å‰µå»ºæ—¥æœŸæ™‚é–“
    local_start = user_tz.localize(datetime.combine(d, time.min))
    local_end = user_tz.localize(datetime.combine(d, time.max))
    
    # è½‰æ›ç‚º UTC
    utc_start = local_start.astimezone(timezone.utc)
    utc_end = local_end.astimezone(timezone.utc)
    
    return utc_start, utc_end

def _build_time_preds(start_d: Optional[date], end_d: Optional[date], col, user_timezone: str = "Asia/Taipei"):
    preds = []
    if start_d and end_d:
        s0, _ = _date_to_utc_range(start_d, user_timezone)
        e0, _ = _date_to_utc_range(end_d, user_timezone)
        preds.extend([col >= s0, col < (e0 + timedelta(days=1))])
    elif start_d:
        s0, e0 = _date_to_utc_range(start_d, user_timezone)
        preds.extend([col >= s0, col < e0])
    elif end_d:
        s0, e0 = _date_to_utc_range(end_d, user_timezone)
        preds.extend([col >= s0, col < e0])
    return preds

def _parse_sort(sort: Optional[str], allowed: dict, default_key: str):
    """
    sort æ ¼å¼ï¼š
      - "field"ï¼ˆé è¨­ descï¼‰
      - "-field" / "+field"
      - "field:asc" / "field:desc"
    """
    if not sort:
        return allowed[default_key].desc()
    raw = sort.strip().lower()
    desc = True
    field = raw
    if ":" in raw:
        field, dir_ = raw.split(":", 1)
        desc = (dir_.strip() == "desc")
    elif raw.startswith("-"):
        field = raw[1:]; desc = True
    elif raw.startswith("+"):
        field = raw[1:]; desc = False
    col = allowed.get(field, allowed[default_key])
    return col.desc() if desc else col.asc()

def _events_keyword_exists_condition(keywords: Optional[str], sr: Optional[List[str]]):
    """
    åœ¨ recordings ä¸Šç”¨ exists å­æŸ¥è©¢éæ¿¾ï¼šé—œéµå­—æ¯”å° *äº‹ä»¶* æ¬„ä½ã€‚
    srï¼šå…è¨± action / scene / summary / objects
    objects ä»¥ã€Œå…ƒç´ ç­‰å€¼åŒ…å«ã€æŸ¥ï¼ˆéœ€è¦å­å­—ä¸²è«‹æ”¹ unnest ILIKEï¼‰ã€‚
    """
    if not keywords:
        return None
    kw = keywords.strip()
    if not kw:
        return None
    scope = set(sr or []) & {"action", "scene", "summary", "objects"}
    if not scope:
        scope = {"summary"}  # ä½ çš„è¦æ ¼ï¼šé è¨­æŸ¥ events.summary
    like = f"%{kw}%"
    preds = []
    from ...DataAccess.tables import events as _ev
    if "action" in scope:   preds.append(_ev.Table.action.ilike(like))
    if "scene" in scope:    preds.append(_ev.Table.scene.ilike(like))
    if "summary" in scope:  preds.append(_ev.Table.summary.ilike(like))
    if "objects" in scope:  preds.append(_ev.Table.objects.contains([kw]))
    if not preds:
        return None
    subq = select(_ev.Table.id).where(and_(_ev.Table.recording_id == recordings_table.Table.id, or_(*preds)))
    return exists(subq)

# ------------------------------------------------------------
# Endpoints
# ------------------------------------------------------------

@recordings_router.get("/{recording_id}", response_model=RecordingUrlResp)
async def get_recording_url(
    request: Request,  # ğŸ”§ ä¿®å¾©ï¼šæ·»åŠ æ¬Šé™æª¢æŸ¥
    recording_id: uuid.UUID = Path(..., description="éŒ„å½±ç‰‡æ®µ ID"),
    ttl: int = Query(900, ge=30, le=7*24*3600, description="URL æœ‰æ•ˆç§’æ•¸ï¼ˆé è¨­ 900ï¼Œæœ€å¤§ 7 å¤©ï¼‰"),
    disposition: Optional[str] = Query(None, regex="^(inline|attachment)$", description="ç€è¦½å™¨å‘ˆç¾æ–¹å¼ï¼šinline æˆ– attachment"),
    filename: Optional[str] = Query(None, description="ä¸‹è¼‰æª”åï¼›æœªæä¾›å‰‡ä½¿ç”¨ s3_key çš„æª”å"),
    asset_type: Optional[str] = Query(None, regex="^(video|thumbnail)$", description="å›å‚³ video æˆ– thumbnail çš„ URL"),
    db: AsyncSession = Depends(get_session),
):
    """
    å–å¾—å½±ç‰‡çš„ **Pre-signed GET URL**ï¼ˆå¯ç›´æ¥æ’­æ”¾/ä¸‹è¼‰ï¼›æ”¯æ´ HTTP Rangeï¼‰ã€‚

    **Query åƒæ•¸**
    - `ttl`: `int`ï¼Œé€£çµæœ‰æ•ˆç§’æ•¸ï¼Œé è¨­ `900`ï¼Œç¯„åœ `30..604800`
    - `disposition`: `inline | attachment`ï¼Œæ§åˆ¶ç€è¦½å™¨é¡¯ç¤ºæˆ–ä¸‹è¼‰
    - `filename`: `str | None`ï¼Œä¸‹è¼‰æª”åï¼ˆæœªæä¾›å‰‡å– `s3_key` å°¾æ®µï¼‰

    **å‘¼å«ç¯„ä¾‹**
    - ç›´æ¥æ’­æ”¾ï¼ˆ5 åˆ†é˜ï¼‰ï¼š  
      `GET /recordings/{id}?ttl=300&disposition=inline`
    - ä¸‹è¼‰ä¸¦æŒ‡å®šæª”åï¼ˆ30 åˆ†é˜ï¼‰ï¼š  
      `GET /recordings/{id}?ttl=1800&disposition=attachment&filename=myvideo.mp4`
    
    **æ³¨æ„**ï¼šæ­¤ç«¯é»åƒ…å›å‚³å½±ç‰‡ URLï¼Œä¸åŒ…å« recording è©³ç´°è³‡è¨Šã€‚
    """
    # ğŸ”§ ä¿®å¾©ï¼šæ·»åŠ æ¬Šé™æª¢æŸ¥
    current_user = request.state.current_user
    from ...DataAccess.tables.__Enumeration import Role
    
    stmt = select(recordings_table.Table).where(recordings_table.Table.id == recording_id)
    rec = (await db.execute(stmt)).scalar_one_or_none()
    if not rec:
        raise HTTPException(status_code=404, detail="recording not found")
    
    # éç®¡ç†å“¡åªèƒ½è¨ªå•è‡ªå·±çš„éŒ„å½±
    if current_user.role != Role.admin and rec.user_id != current_user.id:
        raise HTTPException(status_code=403, detail="æ²’æœ‰æ¬Šé™è¨ªå•æ­¤éŒ„å½±")

    # æ ¹æ“š asset_type åƒæ•¸æ±ºå®šä½¿ç”¨å“ªå€‹ s3_key
    try:
        if asset_type == "thumbnail":
            # éœ€è¦ç¸®åœ–ä½† DB æ²’æœ‰ key
            if not rec.thumbnail_s3_key:
                raise HTTPException(status_code=404, detail="thumbnail not found")
            s3_key = rec.thumbnail_s3_key
            url = _presign_get(s3_key, ttl, disposition=disposition, filename=filename, content_type="image/jpeg")
            now = int(datetime.now(timezone.utc).timestamp())
            return RecordingUrlResp(url=url, ttl=ttl, expires_at=now + ttl)

        # é è¨­å›å½±ç‰‡ï¼ˆasset_type æœªæŒ‡å®šæˆ–ç‚º videoï¼‰
        if not rec.s3_key:
            # éŒ„å½±è³‡æ–™å­˜åœ¨ä½†ç¼ºå°‘ keyï¼Œå±¬æ–¼è³‡æ–™ä¸å®Œæ•´ï¼ˆé€šå¸¸æ˜¯å¯«å…¥æµç¨‹ä¸­æ–·ï¼‰
            raise HTTPException(status_code=409, detail="recording is not ready (missing s3_key)")

        s3_key = rec.s3_key
        url = _presign_get(s3_key, ttl, disposition=disposition, filename=filename, content_type="video/mp4")
        now = int(datetime.now(timezone.utc).timestamp())

        # å¦‚æœæœ‰ç¸®åœ–ï¼ŒåŒæ™‚è¿”å›ç¸®åœ– URLï¼ˆç¸®åœ–å¤±æ•—ä¸æ‡‰è®“å½±ç‰‡ URL ä¹Ÿå¤±æ•—ï¼‰
        thumbnail_url = None
        if rec.thumbnail_s3_key:
            try:
                thumbnail_url = _presign_get(rec.thumbnail_s3_key, ttl, disposition="inline", filename=None, content_type="image/jpeg")
            except Exception as thumb_err:
                print(f"[recordings.get_url] thumbnail presign failed: recording_id={recording_id} err={thumb_err}")

        return RecordingUrlResp(url=url, ttl=ttl, expires_at=now + ttl, thumbnail_url=thumbnail_url)
    except ValueError as e:
        # key æ­£è¦åŒ–éŒ¯èª¤ï¼ˆé€šå¸¸æ˜¯ DB çš„ s3_key æ ¼å¼ä¸æ­£ç¢ºï¼‰
        raise HTTPException(status_code=400, detail=f"Invalid S3 key format: {e}")
    except HTTPException:
        raise
    except Exception as e:
        # boto3 / config / å…¶ä»–æœªé æœŸéŒ¯èª¤ï¼šå›å‚³ 502 ä¸¦åœ¨ server ç«¯å°å‡ºç´°ç¯€
        # æ³¨æ„ï¼šä¸è¦æŠŠæ•æ„Ÿè³‡è¨Šï¼ˆaccess_key/secretï¼‰åå›å‰ç«¯
        print(
            "[recordings.get_url] presign failed:",
            f"recording_id={recording_id}",
            f"bucket={S3_BUCKET}",
            f"internal_endpoint={S3_ENDPOINT}",
            f"public_endpoint={PUBLIC_MINIO_ENDPOINT or '(unset)'}",
            f"err={e}",
        )
        raise HTTPException(status_code=502, detail="Failed to generate presigned URL")


@recordings_router.delete("/{recording_id}", response_model=OkResp, status_code=status.HTTP_200_OK)
async def delete_recording(
    request: Request,  # ğŸ”§ ä¿®å¾©ï¼šæ·»åŠ æ¬Šé™æª¢æŸ¥
    recording_id: uuid.UUID = Path(..., description="éŒ„å½±ç‰‡æ®µ ID"),
    db: AsyncSession = Depends(get_session),
):
    """
    **ç¡¬åˆªé™¤** éŒ„å½±ç‰‡æ®µï¼šåˆª S3 ç‰©ä»¶ + åˆª DB ç´€éŒ„ã€‚  
    è‹¥ `events.recording_id` æ²’æœ‰ `ON DELETE CASCADE`ï¼Œæ­¤è™•æœƒä¸€ä½µåˆªé™¤é—œè¯äº‹ä»¶ã€‚

    **æ­¥é©Ÿ**
    1. è®€å– DB å–å¾— `s3_key`  
    2. åˆªé™¤ S3 ç‰©ä»¶ï¼ˆå†ªç­‰ï¼‰  
    3. åˆªé™¤é—œè¯äº‹ä»¶ï¼ˆè‹¥æœªå•Ÿç”¨ç´šè¯ï¼‰  
    4. åˆªé™¤éŒ„å½±ç´€éŒ„

    **å‘¼å«ç¯„ä¾‹**
    - `DELETE /recordings/{id}`
    """
    # ğŸ”§ ä¿®å¾©ï¼šæ·»åŠ æ¬Šé™æª¢æŸ¥
    current_user = request.state.current_user
    from ...DataAccess.tables.__Enumeration import Role
    
    stmt = select(recordings_table.Table).where(recordings_table.Table.id == recording_id)
    rec = (await db.execute(stmt)).scalar_one_or_none()
    if not rec:
        raise HTTPException(status_code=404, detail="recording not found")
    
    # éç®¡ç†å“¡åªèƒ½åˆªé™¤è‡ªå·±çš„éŒ„å½±
    if current_user.role != Role.admin and rec.user_id != current_user.id:
        raise HTTPException(status_code=403, detail="æ²’æœ‰æ¬Šé™åˆªé™¤æ­¤éŒ„å½±")

    try:
        _delete_object(rec.s3_key)
    except ValueError as e:
        # key æ­£è¦åŒ–éŒ¯èª¤
        raise HTTPException(status_code=400, detail=f"Invalid S3 key format: {e}")
    except Exception as e:
        # å…¶ä»– S3 éŒ¯èª¤
        error_msg = str(e)
        # æå–æ›´å‹å¥½çš„éŒ¯èª¤è¨Šæ¯
        if "XMinioInvalidObjectName" in error_msg or "unsupported characters" in error_msg.lower():
            raise HTTPException(
                status_code=400, 
                detail=f"Invalid S3 object name: {rec.s3_key}. The object name contains unsupported characters."
            )
        raise HTTPException(status_code=502, detail=f"S3 delete failed: {error_msg}")

    # è‹¥ä½ çš„ DB å·²è¨­ CASCADEï¼Œå¯ç§»é™¤ä»¥ä¸‹å…©æ®µ delete
    await db.execute(delete(events_table.Table).where(events_table.Table.recording_id == recording_id))
    await db.execute(delete(recordings_table.Table).where(recordings_table.Table.id == recording_id))
    await db.commit()
    return OkResp()


@recordings_router.get("/", response_model=RecordingListResp)
async def list_recordings(
    request: Request,  # ğŸ”§ ä¿®å¾©ï¼šæ·»åŠ  request åƒæ•¸ä»¥ç²å– current_user
    recording_id: Optional[uuid.UUID] = Query(default=None, description="æŒ‡å®šéŒ„å½± IDï¼ˆç”¨æ–¼ç›´æ¥å®šä½å–®ä¸€å½±ç‰‡ï¼‰"),
    user_id: Optional[int] = Query(default=None, description="æŒ‡å®šä½¿ç”¨è€… IDï¼ˆåƒ…ç®¡ç†å“¡å¯ç”¨ï¼‰"),
    keywords: Optional[str] = Query(None, description="åœ¨ *äº‹ä»¶* æ¬„ä½å…§æœå°‹çš„é—œéµå­—ï¼ˆé è¨­æ¯”å° `summary`ï¼‰"),
    sr: Optional[List[str]] = Query(None, description="æŸ¥è©¢ç¯„åœï¼Œå¤šå€¼ï¼š`?sr=action&sr=scene&sr=objects`ï¼›é è¨­åªæŸ¥ `summary`"),
    start_time: Optional[date] = Query(None, description="ISO local dateï¼›æœƒè½‰ç‚ºæ•´æ—¥ UTC é–‹å§‹"),
    end_time: Optional[date] = Query(None, description="ISO local dateï¼›è‹¥èˆ‡ start_time åŒçµ¦å‰‡å½¢æˆå€é–“"),
    sort: Optional[str] = Query(None, description="æ’åºæ¬„ä½ï¼š`start_time|created_at|duration|size_bytes|id`ï¼›å¯ `:asc|:desc` æˆ– `-field`"),
    page: int = Query(1, ge=1),
    size: int = Query(20, ge=1, le=200),
    db: AsyncSession = Depends(get_session),
):
    """
    æŸ¥è©¢ **å½±ç‰‡åˆ—è¡¨**ï¼ˆäº‹ä»¶é—œéµå­—ã€æ™‚é–“ã€æ’åºã€åˆ†é ï¼‰ã€‚

    **Query åƒæ•¸**
    - `keywords`: `str | None`ï¼Œæœå°‹ *äº‹ä»¶* æ¬„ä½ï¼ˆé è¨­ `summary`ï¼‰
    - `sr`: `List[str] | None`ï¼Œç¯„åœ `action|scene|summary|objects`
    - `start_time`, `end_time`: `date | None`ï¼Œè½‰æ›ç‚ºæ•´æ—¥ UTC ç¯„åœ
    - `sort`: å…è¨± `start_time|created_at|duration|size_bytes|id`ï¼Œå¯ `:asc|:desc` æˆ– `-field`
    - `page`, `size`: åˆ†é 

    **å‘¼å«ç¯„ä¾‹**
    - æ‰¾å‡º 2025-03-01 ç•¶å¤©åŒ…å«ã€Œå–æ°´ã€äº‹ä»¶æ‘˜è¦çš„å½±ç‰‡ï¼š  
      `GET /recordings?keywords=å–æ°´&start_time=2025-03-01&sort=-start_time&page=1&size=20`
    - æŒ‡å®šæŸ¥è©¢ç¯„åœç‚º `action` èˆ‡ `objects`ï¼š  
      `GET /recordings?keywords=drinking&sr=action&sr=objects`
    """
    # ğŸ”§ ä¿®å¾©ï¼šæ·»åŠ ç”¨æˆ¶æ¬Šé™æª¢æŸ¥ï¼ˆéç®¡ç†å“¡åªèƒ½æŸ¥çœ‹è‡ªå·±çš„éŒ„å½±ï¼‰
    current_user = request.state.current_user
    from ...DataAccess.tables.__Enumeration import Role
    
    # ç²å–ä½¿ç”¨è€…æ™‚å€
    user_timezone = user_service.get_user_timezone(current_user)
    
    conds = []
    
    # æ¬Šé™æ§åˆ¶ï¼šä½¿ç”¨è€… ID éæ¿¾
    if current_user.role == Role.admin:
        # ç®¡ç†å“¡ï¼šå¯ä»¥ä½¿ç”¨æ‰‹å‹•è¼¸å…¥çš„ user_idï¼Œå¦‚æœæ²’æœ‰å‰‡ä½¿ç”¨è‡ªå·±çš„ ID
        target_user_id = user_id if user_id is not None else current_user.id
        conds.append(recordings_table.Table.user_id == target_user_id)
    else:
        # ä¸€èˆ¬ä½¿ç”¨è€…ï¼šåªèƒ½æŸ¥è©¢è‡ªå·±çš„å½±ç‰‡ï¼Œå¿½ç•¥æ‰‹å‹•è¼¸å…¥çš„ user_id
        conds.append(recordings_table.Table.user_id == current_user.id)
    
    # --------- å–ã€Œç¬¬ä¸€å€‹äº‹ä»¶ã€çš„æ‘˜è¦/æ™‚é–“ï¼ˆé¿å… N+1ï¼›ä¹Ÿå¯è£œé½Š recordings.start_time ç¼ºå¤±ï¼‰---------
    # ç”¨ window functionï¼šrow_number() over (partition by recording_id order by start_time asc)
    ev = events_table.Table
    first_ev_subq = (
        select(
            ev.recording_id.label("recording_id"),
            ev.start_time.label("event_start_time"),
            ev.summary.label("event_summary"),
            func.row_number()
            .over(
                partition_by=ev.recording_id,
                order_by=ev.start_time.asc().nulls_last(),
            )
            .label("rn"),
        )
        .where(ev.recording_id.is_not(None))
        .subquery("ev_first")
    )

    created_at_col = getattr(recordings_table.Table, "created_at", recordings_table.Table.start_time)
    updated_at_col = getattr(recordings_table.Table, "updated_at", recordings_table.Table.end_time)

    # å½±ç‰‡ã€Œé¡¯ç¤º/æ’åºç”¨ã€çš„æ™‚é–“ï¼šå„ªå…ˆ recordings.start_timeï¼›ç¼ºå¤±æ™‚ç”¨ç¬¬ä¸€å€‹äº‹ä»¶æ™‚é–“ï¼›å†ä¸è¡Œç”¨ created_at
    start_time_expr = func.coalesce(recordings_table.Table.start_time, first_ev_subq.c.event_start_time, created_at_col)

    # æ™‚é–“æ¢ä»¶ï¼ˆä½¿ç”¨ä½¿ç”¨è€…æ™‚å€ï¼‰ï¼Œæ”¹ç”¨ start_time_exprï¼Œé¿å… start_time ç‚º NULL æ™‚æ•´æ‰¹ã€Œçœ‹èµ·ä¾†æŸ¥ä¸åˆ°ã€
    conds += _build_time_preds(start_time, end_time, start_time_expr, user_timezone)

    exists_pred = _events_keyword_exists_condition(keywords, sr)
    if exists_pred is not None:
        conds.append(exists_pred)

    # ç›´æ¥å®šä½å–®ä¸€éŒ„å½±ï¼ˆæ”¯æ´ events â†’ recordings çš„ deep linkï¼‰
    if recording_id:
        conds.append(recordings_table.Table.id == recording_id)

    allowed = {
        "start_time": start_time_expr,
        "created_at": created_at_col,
        "duration": recordings_table.Table.duration,
        "size_bytes": recordings_table.Table.size_bytes,
        "id": recordings_table.Table.id,
    }
    order_by = _parse_sort(sort, allowed, default_key="start_time")

    base_sel = (
        select(
            recordings_table.Table,
            first_ev_subq.c.event_summary.label("first_event_summary"),
            start_time_expr.label("computed_start_time"),
        )
        .select_from(recordings_table.Table)
        .outerjoin(
            first_ev_subq,
            and_(
                first_ev_subq.c.recording_id == recordings_table.Table.id,
                first_ev_subq.c.rn == 1,
            ),
        )
    )
    if conds:
        base_sel = base_sel.where(and_(*conds))

    stmt_items = base_sel.order_by(order_by).offset((page - 1) * size).limit(size)
    # total ç”¨åªé¸ id çš„å­æŸ¥è©¢ï¼Œé¿å…æŠŠ recordings/video_metadata æ•´æ‰¹æ”¾é€²å­æŸ¥è©¢é€ æˆè² æ“”
    base_sel_total = (
        select(recordings_table.Table.id)
        .select_from(recordings_table.Table)
        .outerjoin(
            first_ev_subq,
            and_(
                first_ev_subq.c.recording_id == recordings_table.Table.id,
                first_ev_subq.c.rn == 1,
            ),
        )
    )
    if conds:
        base_sel_total = base_sel_total.where(and_(*conds))
    stmt_total = select(func.count()).select_from(base_sel_total.subquery())

    rows = (await db.execute(stmt_items)).all()
    total = (await db.execute(stmt_total)).scalar_one()
    
    # ğŸ”§ ä¿®å¾©ï¼šä¸€æ¬¡æŸ¥è©¢å°±æ‹¿åˆ° summary/æ™‚é–“ï¼Œä¸¦è½‰æ›æ™‚é–“åˆ°ä½¿ç”¨è€…æ™‚å€
    import pytz
    user_tz = pytz.timezone(user_timezone)
    items_with_summary = []
    for rec, first_summary, computed_start_time in rows:
        # è½‰æ›æ™‚é–“åˆ°ä½¿ç”¨è€…æ™‚å€ï¼ˆstart_timeï¼šç”¨ computed_start_timeï¼‰
        start_time_user = computed_start_time
        if start_time_user:
            if start_time_user.tzinfo is None:
                start_time_user = start_time_user.replace(tzinfo=timezone.utc)
            start_time_user = start_time_user.astimezone(user_tz)

        end_time_user = rec.end_time
        if end_time_user:
            if end_time_user.tzinfo is None:
                end_time_user = end_time_user.replace(tzinfo=timezone.utc)
            end_time_user = end_time_user.astimezone(user_tz)

        created_at_user = getattr(rec, "created_at", None)
        if created_at_user:
            if created_at_user.tzinfo is None:
                created_at_user = created_at_user.replace(tzinfo=timezone.utc)
            created_at_user = created_at_user.astimezone(user_tz)

        updated_at_user = getattr(rec, "updated_at", None)
        if updated_at_user:
            if updated_at_user.tzinfo is None:
                updated_at_user = updated_at_user.replace(tzinfo=timezone.utc)
            updated_at_user = updated_at_user.astimezone(user_tz)
        
        # å°‡ ORM å°è±¡è½‰ç‚º dictï¼Œæ™‚é–“å·²è½‰æ›ç‚ºä½¿ç”¨è€…æ™‚å€
        rec_dict = {
            "id": rec.id,
            "user_id": rec.user_id,
            "camera_id": rec.camera_id,
            "s3_key": rec.s3_key,
            "duration": rec.duration,
            "is_processed": rec.is_processed,
            "is_embedding": rec.is_embedding,
            "size_bytes": rec.size_bytes,
            "upload_status": rec.upload_status.value if hasattr(rec.upload_status, 'value') else str(rec.upload_status),
            "start_time": start_time_user,
            "end_time": end_time_user,
            "video_metadata": rec.video_metadata,
            "summary": first_summary,  # æ·»åŠ  summary
            "thumbnail_s3_key": rec.thumbnail_s3_key,  # æ·»åŠ ç¸®åœ–è·¯å¾‘
            "created_at": created_at_user,
            "updated_at": updated_at_user,
        }
        items_with_summary.append(rec_dict)

    page_total = total // size + (1 if total % size > 0 else 0)
    return RecordingListResp(
        items=items_with_summary,
        item_total=total,
        page_size=size,
        page_now=page,
        page_total=page_total,
        total=total,  # å‘å¾Œç›¸å®¹
    )


@recordings_m2m_router.patch("/{recording_id}/thumbnail")
async def update_recording_thumbnail_m2m(
    recording_id: uuid.UUID = Path(..., description="éŒ„å½± ID"),
    thumbnail_s3_key: str = Query(..., description="ç¸®åœ– S3 è·¯å¾‘"),
    db: AsyncSession = Depends(get_session),
):
    """
    [M2M] æ›´æ–°éŒ„å½±çš„ç¸®åœ–è·¯å¾‘ï¼ˆä¾› ComputeServer å›å¯«ï¼‰ã€‚
    """
    stmt = select(recordings_table.Table).where(recordings_table.Table.id == recording_id)
    result = await db.execute(stmt)
    recording = result.scalar_one_or_none()
    
    if not recording:
        raise HTTPException(status_code=404, detail="éŒ„å½±ä¸å­˜åœ¨")
    
    recording.thumbnail_s3_key = thumbnail_s3_key
    await db.commit()
    await db.refresh(recording)
    
    return {"ok": True, "recording_id": str(recording_id), "thumbnail_s3_key": thumbnail_s3_key}

@recordings_router.get("/{recording_id}/events", response_model=List[EventRead])
async def get_recording_events(
    request: Request,  # ğŸ”§ ä¿®å¾©ï¼šæ·»åŠ æ¬Šé™æª¢æŸ¥
    recording_id: uuid.UUID = Path(..., description="éŒ„å½±ç‰‡æ®µ ID"),
    sort: Optional[str] = Query(None, description="æ’åºï¼š`start_time|created_at|duration|id`ï¼Œå¯ `:asc|:desc` æˆ– `-field`"),
    db: AsyncSession = Depends(get_session),
):
    """
    å–å¾— **æŒ‡å®šéŒ„å½±åº•ä¸‹çš„æ‰€æœ‰äº‹ä»¶**ï¼ˆè¼•é‡ï¼Œç„¡è¤‡é›œ joinï¼‰ã€‚

    **Query åƒæ•¸**
    - `sort`: å…è¨± `start_time|created_at|duration|id`ï¼›å¯ `:asc|:desc` æˆ– `-field`

    **å‘¼å«ç¯„ä¾‹**
    - ä¾äº‹ä»¶é–‹å§‹æ™‚é–“æ–°åˆ°èˆŠï¼š  
      `GET /recordings/{id}/events?sort=-start_time`
    """
    # ğŸ”§ ä¿®å¾©ï¼šæ·»åŠ æ¬Šé™æª¢æŸ¥ï¼ˆå…ˆé©—è­‰ recording æ˜¯å¦å­˜åœ¨ä¸”æœ‰æ¬Šé™è¨ªå•ï¼‰
    current_user = request.state.current_user
    from ...DataAccess.tables.__Enumeration import Role
    
    stmt_rec = select(recordings_table.Table).where(recordings_table.Table.id == recording_id)
    rec = (await db.execute(stmt_rec)).scalar_one_or_none()
    if not rec:
        raise HTTPException(status_code=404, detail="recording not found")
    
    # éç®¡ç†å“¡åªèƒ½è¨ªå•è‡ªå·±çš„éŒ„å½±äº‹ä»¶
    if current_user.role != Role.admin and rec.user_id != current_user.id:
        raise HTTPException(status_code=403, detail="æ²’æœ‰æ¬Šé™è¨ªå•æ­¤éŒ„å½±çš„äº‹ä»¶")
    
    allowed = {
        "start_time": events_table.Table.start_time,
        "created_at": getattr(events_table.Table, "created_at", events_table.Table.start_time),
        "duration": events_table.Table.duration,
        "id": events_table.Table.id,
    }
    order_by = _parse_sort(sort, allowed, default_key="start_time")

    stmt = (
        select(events_table.Table)
        .where(events_table.Table.recording_id == recording_id)
        .order_by(order_by)
    )
    rows = (await db.execute(stmt)).scalars().all()

    # å¾Œç«¯è² è²¬æŠŠäº‹ä»¶æ™‚é–“è½‰æˆä½¿ç”¨è€…æ™‚å€ï¼ˆå‰ç«¯åªé¡¯ç¤ºã€ä¸åšæ™‚å€è¨ˆç®—ï¼‰
    user_timezone = user_service.get_user_timezone(current_user)
    import pytz
    user_tz = pytz.timezone(user_timezone)
    for r in rows:
        if r.start_time:
            if r.start_time.tzinfo is None:
                r.start_time = r.start_time.replace(tzinfo=timezone.utc)
            r.start_time = r.start_time.astimezone(user_tz)
        if hasattr(r, "created_at") and getattr(r, "created_at", None):
            if r.created_at.tzinfo is None:
                r.created_at = r.created_at.replace(tzinfo=timezone.utc)
            r.created_at = r.created_at.astimezone(user_tz)
        if hasattr(r, "updated_at") and getattr(r, "updated_at", None):
            if r.updated_at.tzinfo is None:
                r.updated_at = r.updated_at.replace(tzinfo=timezone.utc)
            r.updated_at = r.updated_at.astimezone(user_tz)
    return rows
