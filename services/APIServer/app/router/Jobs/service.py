# -*- coding: utf-8 -*-
"""
å”¯ä¸€ä¸éœ€è¦æ³¨å…¥API Key æˆ– User ID çš„ router ï¼Œ é‡å°ä¸åŒ Path æ³¨å…¥ä¸åŒçš„ä¾è³´
"""
from __future__ import annotations
from typing import Optional
import uuid
import os
from datetime import datetime, timedelta
import uuid_utils as uuidu
from fastapi import APIRouter, Depends, HTTPException, status, Query
from fastapi.encoders import jsonable_encoder
from sqlalchemy import update, select, func, and_
from sqlalchemy.ext.asyncio import AsyncSession

from ...DataAccess.Connect import get_session
from ...security.deps import get_uploader_api_client, get_compute_api_client, get_current_user
from ...DataAccess.tables.__Enumeration import Role
from .DTO import (
    JobCreateDTO, JobCreatedRespDTO, JobGetRespDTO, JobStatusRespDTO,
    JobCompleteDTO, JobListRespDTO, OKRespDTO
)
from ...DataAccess.task_producer import enqueue
from ...DataAccess.tables import inference_jobs, recordings, events, users
from ...DataAccess.tables.__Enumeration import JobStatus, UploadStatus
from ...router.User.service import UserService
from ...config.path import (
    JOBS_PREFIX, JOBS_POST_CREATE_JOB, JOBS_GET_GET_JOB, JOBS_GET_GET_JOB_STATUS
)

jobs_router = APIRouter(prefix=JOBS_PREFIX, tags=["jobs"])


def create_uuid7() -> uuid.UUID:
    return uuid.UUID(str(uuidu.uuid7()))


def _parse_iso_dt(s: str | None):
    """å°‡ ISO å­—ä¸²(å« Z) è½‰ datetimeï¼›å¤±æ•—å› Noneã€‚"""
    if not s:
        return None
    from datetime import datetime
    try:
        return datetime.fromisoformat(str(s).replace("Z", "+00:00"))
    except Exception:
        return None


@jobs_router.post(JOBS_POST_CREATE_JOB, response_model=JobCreatedRespDTO, status_code=status.HTTP_201_CREATED)
async def create_job(body: JobCreateDTO, db: AsyncSession = Depends(get_session), api_key = Depends(get_uploader_api_client)):
    """å»ºç«‹æ–°çš„æ¨è«–ä»»å‹™ã€‚
    
    ç‚ºå½±ç‰‡è¼¸å…¥å»ºç«‹ recording è¨˜éŒ„ï¼Œå»ºç«‹ pending ç‹€æ…‹çš„ jobï¼Œ
    ä¸¦å°‡ä»»å‹™æŠ•éåˆ° Celery é€²è¡ŒéåŒæ­¥è™•ç†ã€‚
    
    Args:
        body: ä»»å‹™å»ºç«‹è«‹æ±‚è³‡æ–™
        db: è³‡æ–™åº«æœƒè©±
        api_key: API Key é©—è­‰ï¼ˆä¾è³´æ³¨å…¥ï¼‰
        
    Returns:
        JobCreatedRespDTO: åŒ…å« job_id å’Œ trace_id
        
    Raises:
        HTTPException: ç•¶è¼¸å…¥é¡å‹ç‚º video ä½†ç¼ºå°‘ user_id æ™‚
    """
    trace_id: str = body.trace_id or str(create_uuid7())
    params_json = jsonable_encoder(body.params)

    # æ³¨æ„ï¼šAsyncSession é è¨­ autobegin=Trueï¼Œä»»ä½• db.execute éƒ½æœƒè‡ªå‹•é–‹ transactionã€‚
    # å› æ­¤ create_job çš„æ‰€æœ‰ DB æ“ä½œå¿…é ˆæ”¶æ–‚åˆ°å–®ä¸€å€‹ begin()ï¼Œé¿å… nested begin é€ æˆ
    # "A transaction is already begun on this Session."
    async with db.begin():
        # ç²å–ä½¿ç”¨è€…çš„ LLM API Keyï¼ˆåƒ…å°éœ€è¦ LLM è™•ç†çš„ job é¡å‹ï¼‰
        # ç›®å‰åªæœ‰ video_description_extraction éœ€è¦ LLM
        requires_llm = body.type == "video_description_extraction"
        
        if requires_llm:
            if not body.params.user_id:
                raise HTTPException(
                    status_code=400,
                    detail="user_id æ˜¯å¿…éœ€çš„ï¼ˆç”¨æ–¼ç¢ºå®šä½¿ç”¨çš„ LLM API Keyï¼‰"
                )
            
            user_service = UserService()
            user_result = await db.execute(
                select(users.Table).where(users.Table.id == body.params.user_id)
            )
            current_user = user_result.scalar_one_or_none()
            
            if not current_user:
                raise HTTPException(
                    status_code=404,
                    detail=f"ä½¿ç”¨è€… {body.params.user_id} ä¸å­˜åœ¨"
                )

            llm_provider, llm_model, llm_api_key = await user_service.get_user_llm_config(db, current_user)
            if llm_api_key is None:
                llm_api_key = await user_service.get_default_google_api_key(db)

            if llm_api_key:
                params_json["google_api_key"] = llm_api_key
                print(f"[Jobs] å·²ç‚ºä½¿ç”¨è€… {body.params.user_id} è¨­å®š LLM API Key")
            else:
                raise HTTPException(
                    status_code=400,
                    detail=f"ä½¿ç”¨è€… {body.params.user_id} æ²’æœ‰å¯ç”¨çš„ LLM API Keyï¼ˆè«‹è¨­å®šè‡ªå·±çš„ API Key æˆ–ç¢ºä¿ç³»çµ±é è¨­ API Key å·²è¨­å®šï¼‰"
                )

        # å»ºç«‹ recordingsï¼ˆåƒ… video è¼¸å…¥ï¼‰
        recording_id: uuid.UUID | None = None
        if body.input_type == "video":
            # s3_key å»é‡
            res = await db.execute(
                select(recordings.Table).where(recordings.Table.s3_key == body.input_url)
            )
            rec = res.scalar_one_or_none()

            if rec:
                recording_id = rec.id
            else:
                if body.params.user_id is None:
                    raise HTTPException(status_code=400, detail="params.user_id is required for video inputs")

                rec = recordings.Table(
                    user_id=body.params.user_id,
                    camera_id=body.params.camera_id,
                    s3_key=body.input_url,
                    upload_status=UploadStatus.success,
                )
                db.add(rec)
                await db.flush()
                recording_id = rec.id

            if not params_json.get("video_id"):
                params_json["video_id"] = str(recording_id)

        # å»ºç«‹ jobï¼ˆpendingï¼‰
        job = inference_jobs.Table(
            type=body.type,
            input_type=body.input_type,
            input_url=body.input_url,
            status=JobStatus.pending,
            trace_id=trace_id,
            params=params_json,
        )
        db.add(job)
        await db.flush()  # å–å¾— job.id

    # æŠ•é Celeryï¼ˆäº¤æ˜“å¤–ï¼‰
    task_name = {
        "video_description_extraction": "tasks.video_description_extraction",
    }.get(body.type)

    if not task_name:
        # é€™è£¡é–‹ä¸€å€‹ç¨ç«‹äº¤æ˜“æŠŠ job æ¨™æˆ failed
        async with db.begin():
            await db.execute(
                update(inference_jobs.Table)
                .where(inference_jobs.Table.id == job.id)
                .values(status=JobStatus.failed, error_message="Unsupported job type")
            )
        raise HTTPException(status_code=400, detail=f"Unsupported job type: {body.type}")

    payload = {
        "job_id": str(job.id),
        "type": job.type,
        "input_type": job.input_type,
        "input_url": job.input_url,
        "params": params_json,
        "trace_id": trace_id,
    }

    try:
        enqueue(task_name, kwargs={"job": payload}, headers={"X-Trace-Id": trace_id})
    except Exception as e:
        # è‹¥æŠ•éå¤±æ•—ï¼ŒæŠŠ job æ¨™ç‚º failed
        async with db.begin():
            await db.execute(
                update(inference_jobs.Table)
                .where(inference_jobs.Table.id == job.id)
                .values(status=JobStatus.failed, error_message=str(e))
            )
        # å›å‚³ 503ï¼Œä¸¦ä¿ç•™ traceback
        raise HTTPException(status_code=503, detail=f"Enqueue failed: {e}") from e

    return JobCreatedRespDTO(
        job_id=job.id,
        trace_id=trace_id,
        status=JobStatus.pending.value
    )



@jobs_router.get(JOBS_GET_GET_JOB, response_model=JobGetRespDTO)
async def get_job(job_id: str, db: AsyncSession = Depends(get_session), current_user = Depends(get_current_user)):
    """å–å¾— Job ç‹€æ…‹èˆ‡çµæœ"""
    try:
        jid = uuid.UUID(job_id)
    except Exception:
        raise HTTPException(status_code=400, detail="Invalid job_id")

    stmt = select(inference_jobs.Table).where(inference_jobs.Table.id == jid)
    result = await db.execute(stmt)
    job: Optional[inference_jobs.Table] = result.scalar_one_or_none()

    if not job:
        raise HTTPException(status_code=404, detail="Job not found")

    # æ¬Šé™æª¢æŸ¥ï¼šéç®¡ç†å“¡åªèƒ½æŸ¥çœ‹è‡ªå·±ç›¸é—œçš„ä»»å‹™
    if current_user.role != Role.admin:
        # æª¢æŸ¥ä»»å‹™æ˜¯å¦èˆ‡ç•¶å‰ä½¿ç”¨è€…ç›¸é—œ
        job_params = job.params or {}
        job_user_id = job_params.get("user_id")
        
        if job_user_id != current_user.id:
            raise HTTPException(status_code=403, detail="æ²’æœ‰æ¬Šé™æŸ¥çœ‹æ­¤ä»»å‹™")

    return JobGetRespDTO(
        job_id=job.id,
        type=job.type,
        status=job.status.value if hasattr(job.status, "value") else str(job.status),
        input_type=job.input_type,
        input_url=job.input_url,
        output_url=job.output_url,
        trace_id=job.trace_id,
        duration=job.duration,
        error_code=job.error_code,
        error_message=job.error_message,
        params=job.params,
        metrics=job.metrics,
    )


@jobs_router.get(JOBS_GET_GET_JOB_STATUS, response_model=JobStatusRespDTO)
async def get_job_status(job_id: str, db: AsyncSession = Depends(get_session), current_user = Depends(get_current_user)):
    """å–å¾— Job ç‹€æ…‹"""
    try:
        jid = uuid.UUID(job_id)
    except Exception:
        raise HTTPException(status_code=400, detail="Invalid job_id")

    # å…ˆç²å–å®Œæ•´çš„ job è³‡è¨Šä»¥é€²è¡Œæ¬Šé™æª¢æŸ¥
    stmt = select(inference_jobs.Table).where(inference_jobs.Table.id == jid)
    result = await db.execute(stmt)
    job: Optional[inference_jobs.Table] = result.scalar_one_or_none()

    if not job:
        raise HTTPException(status_code=404, detail="Job not found")

    # æ¬Šé™æª¢æŸ¥ï¼šéç®¡ç†å“¡åªèƒ½æŸ¥çœ‹è‡ªå·±ç›¸é—œçš„ä»»å‹™
    if current_user.role != Role.admin:
        job_params = job.params or {}
        job_user_id = job_params.get("user_id")
        
        if job_user_id != current_user.id:
            raise HTTPException(status_code=403, detail="æ²’æœ‰æ¬Šé™æŸ¥çœ‹æ­¤ä»»å‹™")

    return JobStatusRespDTO(status=job.status.value)


@jobs_router.get("/", response_model=JobListRespDTO)
async def list_jobs(
    status_filter: Optional[str] = Query(default=None, description="ç¯©é¸ä»»å‹™ç‹€æ…‹"),
    page: int = Query(1, ge=1),
    size: int = Query(20, ge=1, le=200),
    db: AsyncSession = Depends(get_session),
    current_user = Depends(get_current_user)
):
    """å–å¾—ä»»å‹™åˆ—è¡¨ï¼ˆæ”¯æ´åˆ†é å’Œç‹€æ…‹ç¯©é¸ï¼‰"""
    
    # æ§‹å»ºæŸ¥è©¢æ¢ä»¶
    conditions = []
    
    # æ¬Šé™æ§åˆ¶ï¼šä½¿ç”¨è€… ID éæ¿¾
    if current_user.role == Role.admin:
        # ç®¡ç†å“¡å¯ä»¥æŸ¥çœ‹æ‰€æœ‰ä»»å‹™
        pass
    else:
        # ä¸€èˆ¬ä½¿ç”¨è€…åªèƒ½æŸ¥çœ‹è‡ªå·±çš„ä»»å‹™
        # ä½¿ç”¨ JSON æŸ¥è©¢ä¾†ç¯©é¸ params.user_id
        conditions.append(
            func.json_extract(inference_jobs.Table.params, "$.user_id") == current_user.id
        )
    
    # ç‹€æ…‹ç¯©é¸
    if status_filter:
        try:
            job_status = JobStatus(status_filter)
            conditions.append(inference_jobs.Table.status == job_status)
        except ValueError:
            raise HTTPException(status_code=400, detail=f"Invalid status: {status_filter}")
    
    # æŸ¥è©¢ä»»å‹™
    base_query = select(inference_jobs.Table)
    if conditions:
        base_query = base_query.where(and_(*conditions))
    
    # åˆ†é æŸ¥è©¢
    stmt_items = base_query.order_by(inference_jobs.Table.created_at.desc()).offset((page - 1) * size).limit(size)
    stmt_total = select(func.count()).select_from(base_query.subquery())
    
    rows = (await db.execute(stmt_items)).scalars().all()
    total = (await db.execute(stmt_total)).scalar_one()
    
    # è½‰æ›ç‚º DTO
    items = []
    for job in rows:
        items.append(JobGetRespDTO(
            job_id=job.id,
            type=job.type,
            status=job.status.value if hasattr(job.status, "value") else str(job.status),
            input_type=job.input_type,
            input_url=job.input_url,
            output_url=job.output_url,
            trace_id=job.trace_id,
            duration=job.duration,
            error_code=job.error_code,
            error_message=job.error_message,
            params=job.params,
            metrics=job.metrics,
        ))
    
    return JobListRespDTO(
        items=items,
        total=total,
        page=page,
        size=size,
        page_total=total // size + (1 if total % size > 0 else 0),
    )


@jobs_router.patch("/{job_id}/update_status", response_model=JobStatusRespDTO)
async def update_job_status(job_id: str, new_status: JobStatus, db: AsyncSession = Depends(get_session)):
    """æ›´æ–° Job ç‹€æ…‹ï¼ˆåƒ…é™å…§éƒ¨ä½¿ç”¨ï¼‰"""
    try:
        jid = uuid.UUID(job_id)
    except Exception:
        raise HTTPException(status_code=400, detail="Invalid job_id")

    async with db.begin():
        stmt = (
            update(inference_jobs.Table)
            .where(inference_jobs.Table.id == jid)
            .values(status=new_status)
            .returning(inference_jobs.Table.status)
        )
        result = await db.execute(stmt)
        updated_status: Optional[JobStatus] = result.scalar_one_or_none()
        if not updated_status:
            raise HTTPException(status_code=404, detail="Job not found")

    return JobStatusRespDTO(status=updated_status.value)


@jobs_router.post("/{job_id}/complete", response_model=OKRespDTO)
async def complete_job(job_id: str, body: JobCompleteDTO, db: AsyncSession = Depends(get_session), api_key = Depends(get_compute_api_client)):
    """
    Job å®Œæˆå¾Œçš„å›å‚³ï¼š
    1) æ›´æ–° jobï¼ˆç‹€æ…‹/éŒ¯èª¤/åº¦é‡ï¼‰
    2) è‹¥æˆåŠŸï¼Œæ›´æ–° recordingsï¼ˆis_processed/start_time/end_timeï¼‰
    """
    # é©—è­‰ path èˆ‡ body çš„ job_id ä¸€è‡´
    try:
        jid_path = uuid.UUID(job_id)
        jid_body = uuid.UUID(str(body.job_id))
    except Exception:
        raise HTTPException(status_code=400, detail="Invalid job_id")

    if jid_path != jid_body:
        raise HTTPException(status_code=400, detail="Path job_id and body.job_id mismatch")

    # è½‰ Enum èˆ‡æ™‚é–“ï¼šç›´æ¥ä½¿ç”¨ JobStatus enum å…§çš„å­—ï¼ˆæ­£è¦åŒ–å·²åœ¨ DTO åš strip/lowerï¼‰
    new_status = body.status

    vstart = _parse_iso_dt(body.video_start_time)
    vend = _parse_iso_dt(body.video_end_time)

    async with db.begin():
        # (1) æ›´æ–° jobï¼ˆä¸¦ç¢ºèª job å­˜åœ¨ï¼‰
        res_upd = await db.execute(
            update(inference_jobs.Table)
            .where(inference_jobs.Table.id == jid_body)
            .values(
                status=new_status,
                error_code=body.error_code,
                error_message=body.error_message,
                duration=body.duration,
                metrics=body.metrics,
            )
            .returning(inference_jobs.Table.id)
        )
        updated_id = res_upd.scalar_one_or_none()
        if not updated_id:
            raise HTTPException(status_code=404, detail="Job not found")

        # (1.5) å¯«å…¥ Token ä½¿ç”¨é‡ï¼ˆCompute ä¾†æºï¼‰
        # åªè¦ metrics å¸¶æœ‰ LLM token è³‡è¨Šï¼Œå°±æœƒè¢«çµ±è¨ˆé€²ä½¿ç”¨è€…çš„ Token ä½¿ç”¨é‡
        try:
            res_params = await db.execute(
                select(inference_jobs.Table.params, inference_jobs.Table.type).where(inference_jobs.Table.id == jid_body)
            )
            row = res_params.first()
            job_params = (row[0] if row else None) or {}
            job_type = (row[1] if row else None) or None
            user_id = job_params.get("user_id")

            metrics = body.metrics or {}
            prompt_tokens = metrics.get("llm_prompt_tokens")
            completion_tokens = metrics.get("llm_completion_tokens")
            total_tokens = metrics.get("llm_total_tokens")

            if user_id and (prompt_tokens is not None or completion_tokens is not None or total_tokens is not None):
                from ...utils.llm_usage import log_llm_usage
                usage = {
                    "prompt_tokens": int(prompt_tokens or 0),
                    "completion_tokens": int(completion_tokens or 0),
                    "total_tokens": int(total_tokens or (int(prompt_tokens or 0) + int(completion_tokens or 0))),
                }
                provider = metrics.get("llm_provider")
                model_name = metrics.get("llm_model") or metrics.get("llm_model_name")
                await log_llm_usage(
                    db,
                    user_id=int(user_id),
                    source="compute",
                    provider=str(provider) if provider else None,
                    model_name=str(model_name) if model_name else None,
                    usage=usage,
                    assistant_replies=0,
                    trace_id=body.trace_id,
                    meta={"job_id": str(jid_body), "job_type": job_type},
                )
        except Exception as e:
            print(f"[Jobs] è¨˜éŒ„ compute token ä½¿ç”¨é‡å¤±æ•—: {e}")

        # (2) è‹¥æˆåŠŸ â†’ æ›´æ–° recordings èˆ‡äº‹ä»¶è¡¨
        if new_status == JobStatus.success:
            # å– job.params æ‹¿ video_id
            res = await db.execute(
                select(inference_jobs.Table.params).where(inference_jobs.Table.id == jid_body)
            )
            job_params: Optional[dict] = res.scalar_one_or_none() or {}
            video_id = job_params.get("video_id")
            if not video_id:
                # ä¸è®“ /complete ç›´æ¥å¤±æ•—ï¼šæ”¹æˆæŠŠ job æ¨™è¨˜ failedï¼Œé¿å…å‰ç«¯å¡åœ¨ processing
                await db.execute(
                    update(inference_jobs.Table)
                    .where(inference_jobs.Table.id == jid_body)
                    .values(
                        status=JobStatus.failed,
                        error_code="MISSING_VIDEO_ID",
                        error_message="video_id not found in job params (cannot update recordings/events)",
                    )
                )
                return OKRespDTO()

            try:
                vid = uuid.UUID(str(video_id))
            except Exception:
                await db.execute(
                    update(inference_jobs.Table)
                    .where(inference_jobs.Table.id == jid_body)
                    .values(
                        status=JobStatus.failed,
                        error_code="INVALID_VIDEO_ID",
                        error_message="Invalid video_id in job params (cannot update recordings/events)",
                    )
                )
                return OKRespDTO()

            await db.execute(
                update(recordings.Table)
                .where(recordings.Table.id == vid)
                .values(
                    is_processed=True,
                    duration=body.metrics.get("video_duration_sec") if body.metrics else None,
                    start_time=vstart,
                    end_time=vend
                )
            )
            # events æ–°å¢
            """
            çµæ§‹ç¯„ä¾‹ï¼š
                {
                    "job_id": "test_job",
                    "trace_id": "test_trace",
                    "status": "success",
                    "video_start_time": null,
                    "video_end_time": null,
                    "error_code": null,
                    "error_message": null,
                    "duration": 15.466666666666667, # ä»»å‹™åŸ·è¡Œæ™‚é–“
                    "metrics": {
                        "video_fps": 30.0,
                        "video_total_frames": 254,
                        "video_duration_sec": 8.466666666666667,
                        "target_fps": 2,
                        "effective_fps": 2.0,
                        "extracted_frames": 17,
                        "possible_extracts": 16,
                        "frames_total": 17,
                        "frames_not_blurry": 5,
                        "frames_significant": 17,
                        "frames_captioned": 5,
                        "frames_kept_for_llm": 5,
                        "not_blurry_rate": 0.29411764705882354,
                        "significant_rate": 1.0,
                        "captioned_rate": 0.29411764705882354,
                        "llm_events_count": 1,
                        "index_clamp_count": 0
                    },
                    "events": [
                        {
                            "start_time": 0.0,
                            "end_time": 7.5,
                            "summary": "åœ¨åœè»Šå ´å’Œè¡—é“ä¸Šï¼Œæœ‰äººé¨è‘—è‡ªè¡Œè»Šï¼Œå ´æ™¯ç‚ºå®¤å¤–ã€‚",
                            "objects": [
                                "æ±½è»Š",
                                "è‡ªè¡Œè»Š",
                                "åœè»Šå ´",
                                "è¡—é“"
                            ],
                            "scene": "å®¤å¤–",
                            "action": "é¨è‡ªè¡Œè»Š"
                        }
                    ]
                }
            """
            # å–å¾— recording çš„ user_id / s3_keyï¼ˆå¾ŒçºŒ eventsã€ç¸®åœ–éƒ½æœƒç”¨åˆ°ï¼‰
            res_rec = await db.execute(
                select(recordings.Table.user_id, recordings.Table.s3_key).where(recordings.Table.id == vid)
            )
            rec_row = res_rec.first()
            recording_user_id = rec_row[0] if rec_row else None
            recording_s3_key = rec_row[1] if rec_row else None

            # start_time å„²å­˜UTCæ™‚é–“
            if body.events:
                if not recording_user_id:
                    await db.execute(
                        update(inference_jobs.Table)
                        .where(inference_jobs.Table.id == jid_body)
                        .values(
                            status=JobStatus.failed,
                            error_code="RECORDING_USER_NOT_FOUND",
                            error_message="recording user_id not found (cannot create events)",
                        )
                    )
                    return OKRespDTO()
                
                for event in body.events:
                    ev = events.Table(
                        user_id=recording_user_id,  # ğŸ”§ ä¿®å¾©ï¼šæ·»åŠ  user_id
                        recording_id=vid,
                        action=event.get("action"),
                        scene=event.get("scene"),
                        summary=event.get("summary"),
                        objects=event.get("objects"),
                        embedding=event.get("embedding"), # 10/20/2025 Add embedding
                        start_time=vstart + timedelta(seconds=event.get("start_time")) if vstart and event.get("start_time") is not None else None,
                        duration=event.get("end_time") - event.get("start_time") if event.get("end_time") is not None and event.get("start_time") is not None else None
                    )
                    db.add(ev)
                
                # æäº¤äº‹ä»¶åˆ°è³‡æ–™åº«
                await db.commit()
                
                # å¦‚æœäº‹ä»¶ä¸­æ²’æœ‰ embedding,å‰‡è§¸ç™¼ embedding ç”Ÿæˆä»»å‹™
                has_embedding = any(event.get("embedding") for event in body.events)
                if not has_embedding:
                    try:
                        from ...DataAccess.task_producer import enqueue

                        # å»ºç«‹ inference_jobs è¿½è¹¤ï¼ˆembedding_generationï¼‰
                        emb_job = inference_jobs.Table(
                            type="embedding_generation",
                            status=JobStatus.pending,
                            input_type="recording",
                            input_url=str(vid),
                            output_url=None,
                            trace_id=body.trace_id,
                            params={
                                "user_id": int(recording_user_id) if recording_user_id is not None else None,
                                "recording_id": str(vid),
                                "progress": 0.0,
                            },
                            metrics=None,
                        )
                        db.add(emb_job)
                        await db.commit()
                        await db.refresh(emb_job)

                        enqueue("tasks.generate_embeddings_for_recording", {
                            "recording_id": str(vid),
                            "job_id": str(emb_job.id),
                        })
                        print(f"[Job] å·²è§¸ç™¼ embedding ç”Ÿæˆä»»å‹™: recording_id={vid} job_id={emb_job.id}")
                    except Exception as e:
                        print(f"[Job] è§¸ç™¼ embedding ç”Ÿæˆä»»å‹™å¤±æ•—: {e}")
                
            # ç¸®åœ–ç”Ÿæˆå·²ä½µå…¥ ComputeServer çš„ videosprocessingï¼ˆåŒä¸€æ”¯ä»»å‹™ä½¿ç”¨è¨˜æ†¶é«”å¹€ç›´æ¥ç”¢ç”Ÿç¸®åœ–ä¸¦å›å¯«ï¼‰
            # å› æ­¤é€™è£¡ä¸å† enqueue tasks.generate_video_thumbnailï¼Œé¿å…é‡è¤‡å·¥ä½œèˆ‡ç«¶æ…‹ã€‚
    
    return OKRespDTO()
