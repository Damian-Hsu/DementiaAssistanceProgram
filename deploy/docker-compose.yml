services:
  postgres:
    image: pgvector/pgvector:pg15
    container_name: demo_postgres
    restart: always
    environment:
      POSTGRES_USER: ${DB_SUPERUSER}
      POSTGRES_PASSWORD: ${DB_SUPERPASS}
      POSTGRES_DB: ${DB_NAME}
    ports:
      - "${DB_PORT_PUBLIC}:${DB_PORT}"
    volumes:
      - ../datas/postgres_data:/var/lib/postgresql/data
      - ./postgres/init-scripts:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_SUPERUSER} -d ${DB_NAME}"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - demo-network
  # fluent-bit:
  #   image: fluent/fluent-bit:2.2
  #   container_name: demo_fluent-bit
  #   ports: ["24224:24224"]
  #   volumes:
  #     - ../datas/logs:/logs
  #     - ./fluent-bit/fluent-bit.conf:/fluent-bit/etc/fluent-bit.conf:ro
  #   command: ["-c", "/fluent-bit/etc/fluent-bit.conf"]
  #   networks:
  #     - demo-network

  redis:
    image: redis:7
    container_name: demo_redis
    restart: always
    # 端口不直接暴露，這是內部服務
    # ports: ["30600:6379"]
    command: ["redis-server", "--save", "", "--appendonly", "no"]
    networks:
      - demo-network

  minio:
    image: minio/minio:latest
    container_name: demo_minio
    restart: always
    env_file:
      - .env
    command: >
      server
      --console-address ":9001"
      /data1 /data2 /data3 /data4

    #如果要Demo可以使用
    #command: server --console-address ":9001" /data
    #volumes:
    #  - ../datas/minio/data:/data
    # MinIO 端口配置
    # 注意：presigned URLs 無法通過 Nginx 代理，因為簽名是基於完整路徑的
    # Nginx 重寫路徑會導致簽名驗證失敗
    # 因此，MinIO API 端口需要直接暴露，用於 presigned URLs
    # MinIO Console 可以通過 Nginx 代理（/minio-console/）
    ports:
      - "30300:9000"  # MinIO API（必須直接暴露，用於 presigned URLs）
    #   - "30301:9001"  # MinIO Console（可選，用於管理，可通過 Nginx 代理）
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://127.0.0.1:9000/minio/health/live || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
    volumes:
      - ../datas/minio_data/data1:/data1
      - ../datas/minio_data/data2:/data2
      - ../datas/minio_data/data3:/data3
      - ../datas/minio_data/data4:/data4
    
    networks:
      - demo-network
  minio-init:
    image: minio/mc:latest
    depends_on:
      minio:
        condition: service_healthy
    env_file:
      - .env
    volumes:
      - ./minio/init-bucket.sh:/init-bucket.sh:ro
    entrypoint: ["/bin/sh", "/init-bucket.sh"]
    networks:
      - demo-network

  mediamtx:
    image: bluenviron/mediamtx:latest
    container_name: mediamtx
    restart: unless-stopped
    volumes:
      - ./mediamtx/mediamtx.yml:/mediamtx.yml:ro   # 放到你 repo 裡的某處
      - ../datas/streaming/recordings:/recordings
    environment:
      - MTX_PATH=/mediamtx.yml
    # 端口配置：
    # - RTSP: 通過 Nginx 的 8554 端口（stream 模組 TCP）
    # - HLS: 通過 Nginx 的 /hls/ 路徑（HTTP 80/443）
    # - WebRTC HTTP/WHEP: 通過 Nginx 的 /webrtc/ 路徑（HTTP 80/443）
    # - WebRTC ICE/UDP: ✅ 建議「直接暴露」在宿主機 UDP（不要走 Nginx UDP proxy，ICE 會因來源位址/port 不一致而失敗）
    ports:
    #   - "30201:8554/tcp" # RTSP（已通過 Nginx 8554 端口代理）
    #   - "30202:8888/tcp" # HLS（已通過 Nginx /hls/ 路徑代理）
    #   - "30204:8889/tcp" # WebRTC (HTTP/WHEP)（已通過 Nginx /webrtc/ 路徑代理）
      - "30205:30205/udp" # WebRTC (ICE/UDP)（直接暴露，讓封包來源維持 192.168.191.20:30205）
    networks:
      - demo-network
  api:
    build:
      context: ../services/APIServer
      dockerfile: Dockerfile.api
    container_name: api_server
    restart: unless-stopped
    env_file: [.env]
    environment:
      - LOG_DIR=/var/log/api
    volumes:
      - ../datas/logs/api:/var/log/api
    # 端口不直接暴露，通過 Nginx 反向代理訪問（/api/）
    # ports:
    #   - "30000:30000"
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://127.0.0.1:30000/api/v1/healthz || exit 1"]
      interval: 60s
      timeout: 5s
      retries: 5
    networks: [demo-network]
    depends_on:
      - postgres
      - redis
      - minio

  compute:
    build:
      context: ../services/ComputeServer
      dockerfile: Dockerfile.compute
    container_name: compute_server
    restart: unless-stopped
    env_file: [.env]
    environment:
      - LOG_DIR=/var/log/compute
      - HF_HOME=/srv/app/adapters/.cache/huggingface
    volumes:
      - ../datas/logs/compute:/var/log/compute
      - ../datas/compute/adapters:/srv/app/adapters:rw
    networks: [demo-network]
    depends_on:
      - mediamtx
      - minio
      - minio-init
      - api
      - redis
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all            # 想用幾張卡；用 all 代表全部
              capabilities: [gpu] # 必填：要求的是 GPU 能力
  streaming:
    build:
      context: ../services/StreamingServer
      dockerfile: Dockerfile.streaming
    container_name: streaming_server
    restart: unless-stopped
    env_file: [.env]
    environment:
      - RECORD_ROOT=/recordings
      - LOG_DIR=/var/log/streaming
      - UPLOADER_DB=/recordings/uploader.db
    volumes:
      - ../datas/streaming/recordings:/recordings
      - ../datas/logs/streaming:/var/log/streaming
    # 端口不直接暴露，這是內部服務，只供 API Server 調用
    # ports:
    #   - "30500:30500"
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://127.0.0.1:30500/healthz || exit 1"]
      interval: 60s
      timeout: 5s
      retries: 5
    networks: [demo-network]
    depends_on:
      - mediamtx
      - minio
      - minio-init
      - api
      - compute
  webui:
    build:
      context: ../services/WebUIServer
      dockerfile: Dockerfile.webui
    container_name: webui_server
    restart: unless-stopped
    env_file: [.env]
    # ports:
    #   - "30100:30100"
    networks: [demo-network]
    depends_on:
      - api

  nginx:
    image: nginx:alpine
    container_name: nginx_proxy
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
      - "8554:8554"      # RTSP TCP 代理端口
      # WebRTC ICE/UDP 不走 Nginx（改由 mediamtx 直接暴露 30205/udp）
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ../datas/logs/nginx:/var/log/nginx
    networks: [demo-network]
    depends_on:
      - api
      - webui
      - mediamtx
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost/healthz || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

networks:
  demo-network:
    driver: bridge